"""
Streamlit App - Giao diá»‡n huáº¥n luyá»‡n ML Fraud Detection
========================================================
á»¨ng dá»¥ng web Ä‘á»ƒ huáº¥n luyá»‡n vÃ  quáº£n lÃ½ cÃ¡c mÃ´ hÃ¬nh ML
cho há»‡ thá»‘ng phÃ¡t hiá»‡n giao dá»‹ch lá»«a Ä‘áº£o.

Features:
- Huáº¥n luyá»‡n Layer 1 models (Isolation Forest, LightGBM)
- Huáº¥n luyá»‡n Layer 2 models (Autoencoder, LSTM, GNN)
- GNN vá»›i 2 bÆ°á»›c: Táº¡o máº¡ng lÆ°á»›i + Huáº¥n luyá»‡n
- Xem metrics vÃ  Ä‘Ã¡nh giÃ¡ model

Author: Senior ML Engineer
Version: 2.0.0
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, Any, Optional

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ThÃªm path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import get_config

config = get_config()

# ========== PAGE CONFIG ==========
st.set_page_config(
    page_title="ML Fraud Detection - Training Dashboard",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== CUSTOM CSS ==========
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #424242;
        border-bottom: 2px solid #1E88E5;
        padding-bottom: 0.5rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .success-box {
        background-color: #E8F5E9;
        border-left: 4px solid #4CAF50;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FFF3E0;
        border-left: 4px solid #FF9800;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #FFEBEE;
        border-left: 4px solid #F44336;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #E3F2FD;
        border-left: 4px solid #2196F3;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        border-radius: 10px;
        height: 3rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


# ========== HELPER FUNCTIONS ==========
def check_gnn_data_exists(data_dir: str) -> Dict[str, bool]:
    """Kiá»ƒm tra cÃ¡c file dá»¯ liá»‡u GNN cÃ³ tá»“n táº¡i khÃ´ng"""
    required_files = {
        'nodes.csv': False,
        'edges_transfer.csv': False,
        'edge_labels.csv': False,
        'splits.csv': False
    }

    optional_files = {
        'edges_uses_device.csv': False,
        'edges_uses_ip.csv': False,
        'metadata.json': False,
        'nodes_user.csv': False,
        'nodes_recipient.csv': False,
        'nodes_device.csv': False,
        'nodes_ip.csv': False
    }

    for file in required_files:
        required_files[file] = os.path.exists(os.path.join(data_dir, file))

    for file in optional_files:
        optional_files[file] = os.path.exists(os.path.join(data_dir, file))

    # nodes.csv cÃ³ thá»ƒ Ä‘Æ°á»£c thay tháº¿ bá»Ÿi cÃ¡c file nodes_*.csv
    if not required_files['nodes.csv']:
        if optional_files['nodes_user.csv'] or optional_files['nodes_recipient.csv']:
            required_files['nodes.csv'] = True

    return {
        'required': required_files,
        'optional': optional_files,
        'all_required_exist': all(required_files.values())
    }


def check_graph_ready(data_dir: str) -> bool:
    """Kiá»ƒm tra graph Ä‘Ã£ Ä‘Æ°á»£c build chÆ°a"""
    flag_path = os.path.join(data_dir, 'graph_ready.flag')
    graph_path = os.path.join(data_dir, 'hetero_graph.pt')
    return os.path.exists(flag_path) and os.path.exists(graph_path)


def check_model_exists(model_name: str) -> bool:
    """Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c train chÆ°a"""
    model_paths = {
        'gnn': os.path.join(config.SAVED_MODELS_DIR, 'gnn_hetero.pth'),
        'lstm': os.path.join(config.SAVED_MODELS_DIR, 'lstm.pth'),
        'autoencoder': os.path.join(config.SAVED_MODELS_DIR, 'autoencoder.pth'),
        'lightgbm': os.path.join(config.SAVED_MODELS_DIR, 'lightgbm.pkl'),
        'isolation_forest': os.path.join(config.SAVED_MODELS_DIR, 'isolation_forest.pkl')
    }
    return os.path.exists(model_paths.get(model_name, ''))


def format_number(num: float, decimals: int = 4) -> str:
    """Format sá»‘ vá»›i sá»‘ chá»¯ sá»‘ tháº­p phÃ¢n"""
    return f"{num:.{decimals}f}"


def create_metrics_chart(history: Dict) -> go.Figure:
    """Táº¡o biá»ƒu Ä‘á»“ metrics trong quÃ¡ trÃ¬nh training"""
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Loss', 'ROC-AUC', 'F1-Score', 'Learning Progress')
    )

    epochs = list(range(1, len(history.get('train_loss', [])) + 1))

    # Loss
    if 'train_loss' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['train_loss'], name='Train Loss', line=dict(color='blue')), row=1, col=1)
    if 'val_loss' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['val_loss'], name='Val Loss', line=dict(color='red')), row=1, col=1)

    # AUC
    if 'train_auc' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['train_auc'], name='Train AUC', line=dict(color='blue')), row=1, col=2)
    if 'val_auc' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['val_auc'], name='Val AUC', line=dict(color='red')), row=1, col=2)

    # F1
    if 'train_f1' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['train_f1'], name='Train F1', line=dict(color='blue')), row=2, col=1)
    if 'val_f1' in history:
        fig.add_trace(go.Scatter(x=epochs, y=history['val_f1'], name='Val F1', line=dict(color='red')), row=2, col=1)

    fig.update_layout(height=500, showlegend=True)
    return fig


def create_confusion_matrix_chart(cm: list, labels: list = ['Normal', 'Fraud']) -> go.Figure:
    """Táº¡o biá»ƒu Ä‘á»“ confusion matrix"""
    cm_array = np.array(cm)

    fig = go.Figure(data=go.Heatmap(
        z=cm_array,
        x=labels,
        y=labels,
        colorscale='Blues',
        text=cm_array,
        texttemplate='%{text}',
        textfont={"size": 16},
        hovertemplate='Actual: %{y}<br>Predicted: %{x}<br>Count: %{z}<extra></extra>'
    ))

    fig.update_layout(
        title='Confusion Matrix',
        xaxis_title='Predicted',
        yaxis_title='Actual',
        height=400
    )

    return fig


# ========== SIDEBAR ==========
def render_sidebar():
    """Render sidebar navigation"""
    st.sidebar.markdown("# ğŸ¤– ML Training")
    st.sidebar.markdown("---")

    page = st.sidebar.radio(
        "Chá»n trang:",
        ["ğŸ  Tá»•ng quan", "ğŸ¯ Layer 1", "ğŸ§  Layer 2", "ğŸ•¸ï¸ GNN Training"],
        index=3  # Máº·c Ä‘á»‹nh chá»n GNN Training
    )

    st.sidebar.markdown("---")

    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i models
    st.sidebar.markdown("### ğŸ“Š Tráº¡ng thÃ¡i Models")

    models_status = {
        'Isolation Forest': check_model_exists('isolation_forest'),
        'LightGBM': check_model_exists('lightgbm'),
        'Autoencoder': check_model_exists('autoencoder'),
        'LSTM': check_model_exists('lstm'),
        'GNN': check_model_exists('gnn')
    }

    for model, exists in models_status.items():
        status = "âœ…" if exists else "âŒ"
        st.sidebar.markdown(f"{status} {model}")

    return page


# ========== MAIN PAGES ==========
def render_overview_page():
    """Trang tá»•ng quan"""
    st.markdown('<h1 class="main-header">ğŸ¤– ML Fraud Detection Training Dashboard</h1>', unsafe_allow_html=True)

    st.markdown("""
    ### ChÃ o má»«ng Ä‘áº¿n vá»›i há»‡ thá»‘ng huáº¥n luyá»‡n ML Fraud Detection

    Há»‡ thá»‘ng nÃ y cho phÃ©p báº¡n:
    - ğŸ¯ **Layer 1**: Huáº¥n luyá»‡n Isolation Forest vÃ  LightGBM
    - ğŸ§  **Layer 2**: Huáº¥n luyá»‡n Autoencoder, LSTM vÃ  GNN
    - ğŸ“Š **ÄÃ¡nh giÃ¡**: Xem metrics vÃ  Ä‘Ã¡nh giÃ¡ model

    #### Kiáº¿n trÃºc há»‡ thá»‘ng:
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **Layer 1 - Fast Detection:**
        - Isolation Forest: PhÃ¡t hiá»‡n anomaly nhanh
        - LightGBM: Classification vá»›i gradient boosting

        **Layer 2 - Deep Analysis:**
        - Autoencoder: Reconstruction-based anomaly
        - LSTM: Sequence-based detection
        - GNN: Graph-based fraud detection
        """)

    with col2:
        st.markdown("""
        **Quy trÃ¬nh GNN:**
        1. Upload dá»¯ liá»‡u vÃ o thÆ° má»¥c `gnn_data/`
        2. Báº¥m "Táº¡o máº¡ng lÆ°á»›i GNN" Ä‘á»ƒ build graph
        3. Báº¥m "Huáº¥n luyá»‡n GNN" Ä‘á»ƒ train model
        4. ÄÃ¡nh giÃ¡ vÃ  sá»­ dá»¥ng model

        **LÆ°u Ã½:**
        - Graph pháº£i Ä‘Æ°á»£c build trÆ°á»›c khi train
        - Model Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng sau khi train
        """)


def render_layer1_page():
    """Trang Layer 1 training"""
    st.markdown('<h2 class="section-header">ğŸ¯ Layer 1 - Fast Detection Models</h2>', unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### Isolation Forest")
        st.markdown("PhÃ¡t hiá»‡n anomaly dá»±a trÃªn isolation cá»§a data points.")

        if st.button("ğŸŒ² Huáº¥n luyá»‡n Isolation Forest", key="train_if"):
            with st.spinner("Äang huáº¥n luyá»‡n Isolation Forest..."):
                st.info("Feature Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn...")

    with col2:
        st.markdown("### LightGBM")
        st.markdown("Gradient boosting cho binary classification.")

        if st.button("ğŸš€ Huáº¥n luyá»‡n LightGBM", key="train_lgbm"):
            with st.spinner("Äang huáº¥n luyá»‡n LightGBM..."):
                st.info("Feature Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn...")


def render_layer2_page():
    """Trang Layer 2 training"""
    st.markdown('<h2 class="section-header">ğŸ§  Layer 2 - Deep Learning Models</h2>', unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["Autoencoder", "LSTM", "GNN"])

    with tab1:
        st.markdown("### Autoencoder")
        st.markdown("Reconstruction-based anomaly detection.")
        if st.button("ğŸ”„ Huáº¥n luyá»‡n Autoencoder", key="train_ae"):
            st.info("Feature Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn...")

    with tab2:
        st.markdown("### LSTM")
        st.markdown("Sequence-based fraud detection.")
        if st.button("ğŸ“ˆ Huáº¥n luyá»‡n LSTM", key="train_lstm"):
            st.info("Feature Ä‘ang Ä‘Æ°á»£c phÃ¡t triá»ƒn...")

    with tab3:
        st.markdown("### GNN")
        st.markdown("Graph-based fraud detection. Xem trang **GNN Training** Ä‘á»ƒ huáº¥n luyá»‡n.")


def render_gnn_training_page():
    """Trang huáº¥n luyá»‡n GNN vá»›i 2 bÆ°á»›c riÃªng biá»‡t"""
    st.markdown('<h2 class="section-header">ğŸ•¸ï¸ GNN Fraud Detection - Huáº¥n luyá»‡n mÃ´ hÃ¬nh</h2>', unsafe_allow_html=True)

    # Cáº¥u hÃ¬nh thÆ° má»¥c dá»¯ liá»‡u
    default_data_dir = os.path.join(config.BASE_DIR, 'gnn_data')

    st.markdown("### ğŸ“ Cáº¥u hÃ¬nh dá»¯ liá»‡u")

    data_dir = st.text_input(
        "ThÆ° má»¥c dá»¯ liá»‡u GNN:",
        value=default_data_dir,
        help="ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a cÃ¡c file CSV/JSON cho GNN"
    )

    # Kiá»ƒm tra dá»¯ liá»‡u
    data_status = check_gnn_data_exists(data_dir)
    graph_ready = check_graph_ready(data_dir)

    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i dá»¯ liá»‡u
    with st.expander("ğŸ“‹ Tráº¡ng thÃ¡i dá»¯ liá»‡u", expanded=True):
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Files báº¯t buá»™c:**")
            for file, exists in data_status['required'].items():
                status = "âœ…" if exists else "âŒ"
                st.markdown(f"{status} `{file}`")

        with col2:
            st.markdown("**Files tÃ¹y chá»n:**")
            for file, exists in data_status['optional'].items():
                if exists:
                    st.markdown(f"âœ… `{file}`")

        with col3:
            st.markdown("**Tráº¡ng thÃ¡i:**")
            if data_status['all_required_exist']:
                st.success("âœ… Dá»¯ liá»‡u Ä‘áº§y Ä‘á»§")
            else:
                st.error("âŒ Thiáº¿u dá»¯ liá»‡u báº¯t buá»™c")

            if graph_ready:
                st.success("âœ… Graph Ä‘Ã£ sáºµn sÃ ng")
            else:
                st.warning("âš ï¸ Graph chÆ°a Ä‘Æ°á»£c táº¡o")

    st.markdown("---")

    # ========== 2 NÃšT RIÃŠNG BIá»†T ==========
    st.markdown("### ğŸ® Äiá»u khiá»ƒn huáº¥n luyá»‡n")

    col1, col2 = st.columns(2)

    # ========== NÃšT 1: Táº O Máº NG LÆ¯á»šI GNN ==========
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    padding: 1.5rem; border-radius: 15px; color: white; margin-bottom: 1rem;">
            <h3 style="margin: 0; color: white;">ğŸ•¸ï¸ BÆ¯á»šC 1: Táº¡o máº¡ng lÆ°á»›i</h3>
            <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">
                Load dá»¯ liá»‡u, kiá»ƒm tra tÃ­nh toÃ n váº¹n vÃ  xÃ¢y dá»±ng Heterogeneous Graph
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Disable náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u
        build_disabled = not data_status['all_required_exist']

        if st.button(
            "ğŸ•¸ï¸ Táº¡o máº¡ng lÆ°á»›i GNN",
            key="build_graph",
            disabled=build_disabled,
            help="Load dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng graph PyTorch Geometric"
        ):
            run_build_graph(data_dir)

        if build_disabled:
            st.warning("âš ï¸ Cáº§n upload Ä‘áº§y Ä‘á»§ dá»¯ liá»‡u trÆ°á»›c khi táº¡o máº¡ng lÆ°á»›i")

    # ========== NÃšT 2: HUáº¤N LUYá»†N GNN ==========
    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
                    padding: 1.5rem; border-radius: 15px; color: white; margin-bottom: 1rem;">
            <h3 style="margin: 0; color: white;">ğŸ¤– BÆ¯á»šC 2: Huáº¥n luyá»‡n model</h3>
            <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">
                Train GNN model vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t trÃªn táº­p test
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Disable náº¿u graph chÆ°a sáºµn sÃ ng
        train_disabled = not graph_ready

        if st.button(
            "ğŸ¤– Huáº¥n luyá»‡n GNN",
            key="train_gnn",
            disabled=train_disabled,
            help="Train GNN model (yÃªu cáº§u graph Ä‘Ã£ Ä‘Æ°á»£c táº¡o)"
        ):
            run_train_gnn(data_dir)

        if train_disabled:
            st.warning("âš ï¸ Cáº§n táº¡o máº¡ng lÆ°á»›i GNN trÆ°á»›c khi huáº¥n luyá»‡n")

    st.markdown("---")

    # ========== Cáº¤U HÃŒNH NÃ‚NG CAO ==========
    with st.expander("âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao", expanded=False):
        col1, col2, col3 = st.columns(3)

        with col1:
            epochs = st.number_input("Sá»‘ epochs:", min_value=10, max_value=500, value=100)
            learning_rate = st.number_input("Learning rate:", min_value=0.0001, max_value=0.1, value=0.01, format="%.4f")

        with col2:
            hidden_dim = st.selectbox("Hidden dimension:", [32, 64, 128, 256], index=1)
            num_layers = st.selectbox("Sá»‘ GNN layers:", [2, 3, 4], index=1)

        with col3:
            dropout = st.slider("Dropout:", 0.0, 0.5, 0.3)
            patience = st.number_input("Early stopping patience:", min_value=5, max_value=50, value=15)

        # LÆ°u config vÃ o session state
        st.session_state['gnn_config'] = {
            'epochs': epochs,
            'learning_rate': learning_rate,
            'hidden_channels': hidden_dim,
            'num_layers': num_layers,
            'dropout': dropout,
            'patience': patience
        }

    # ========== HIá»‚N THá»Š Káº¾T QUáº¢ ==========
    if 'gnn_results' in st.session_state:
        st.markdown("---")
        st.markdown("### ğŸ“Š Káº¿t quáº£ huáº¥n luyá»‡n")

        results = st.session_state['gnn_results']

        # Metrics cards
        col1, col2, col3, col4, col5 = st.columns(5)

        metrics = results.get('test', results.get('val', {}))

        with col1:
            st.metric("Accuracy", format_number(metrics.get('accuracy', 0)))
        with col2:
            st.metric("Precision", format_number(metrics.get('precision', 0)))
        with col3:
            st.metric("Recall", format_number(metrics.get('recall', 0)))
        with col4:
            st.metric("F1-Score", format_number(metrics.get('f1_score', 0)))
        with col5:
            st.metric("ROC-AUC", format_number(metrics.get('roc_auc', 0)))

        # Charts
        col1, col2 = st.columns(2)

        with col1:
            if 'history' in results:
                st.plotly_chart(create_metrics_chart(results['history']), use_container_width=True)

        with col2:
            if 'confusion_matrix' in metrics:
                st.plotly_chart(create_confusion_matrix_chart(metrics['confusion_matrix']), use_container_width=True)

    # ========== HIá»‚N THá»Š THá»NG KÃŠ GRAPH ==========
    if 'graph_stats' in st.session_state:
        st.markdown("---")
        st.markdown("### ğŸ“ˆ Thá»‘ng kÃª Graph")

        stats = st.session_state['graph_stats']

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Nodes:**")
            if 'nodes' in stats:
                st.write(f"Tá»•ng: {stats['nodes'].get('total', 0):,}")
                if 'by_type' in stats['nodes']:
                    for nt, count in stats['nodes']['by_type'].items():
                        st.write(f"  - {nt}: {count:,}")

        with col2:
            st.markdown("**Edges:**")
            if 'edges' in stats:
                for et, count in stats['edges'].items():
                    st.write(f"  - {et}: {count:,}")

        with col3:
            st.markdown("**Labels:**")
            if 'labels' in stats:
                st.write(f"Tá»•ng: {stats['labels'].get('total', 0):,}")
                st.write(f"Fraud ratio: {stats['labels'].get('fraud_ratio', 0)*100:.2f}%")


def run_build_graph(data_dir: str):
    """Cháº¡y quÃ¡ trÃ¬nh xÃ¢y dá»±ng graph"""
    st.markdown("---")
    st.markdown("### ğŸ”„ Äang xÃ¢y dá»±ng máº¡ng lÆ°á»›i GNN...")

    progress_bar = st.progress(0)
    status_text = st.empty()
    log_container = st.container()

    try:
        # Import pipeline
        from preprocessing.gnn_data_pipeline import GNNDataPipeline

        # BÆ°á»›c 1: Load dá»¯ liá»‡u
        status_text.text("ğŸ“ BÆ°á»›c 1/4: Load dá»¯ liá»‡u...")
        progress_bar.progress(10)

        pipeline = GNNDataPipeline(data_dir, verbose=False)
        load_results = pipeline.load_all_data()

        with log_container:
            st.success(f"âœ… Loaded {len(load_results['files_loaded'])} files")
            for f in load_results['files_loaded']:
                st.write(f"  - {f}")

        if not load_results['success']:
            st.error(f"âŒ Lá»—i load dá»¯ liá»‡u: {load_results['errors']}")
            return

        progress_bar.progress(30)

        # BÆ°á»›c 2: Sanity check
        status_text.text("ğŸ” BÆ°á»›c 2/4: Kiá»ƒm tra tÃ­nh toÃ n váº¹n...")

        try:
            check_results = pipeline.sanity_check()
            with log_container:
                st.success(f"âœ… Sanity check passed: {check_results['checks_passed']}/{check_results['checks_performed']} checks")
        except ValueError as e:
            with log_container:
                st.error(f"âŒ Sanity check failed: {str(e)}")
            return

        progress_bar.progress(50)

        # BÆ°á»›c 3: Build graph
        status_text.text("ğŸ”¨ BÆ°á»›c 3/4: XÃ¢y dá»±ng Heterogeneous Graph...")

        data = pipeline.build_hetero_graph()

        with log_container:
            st.success(f"âœ… Graph built: {len(data.node_types)} node types, {len(data.edge_types)} edge types")

        progress_bar.progress(80)

        # BÆ°á»›c 4: Save graph
        status_text.text("ğŸ’¾ BÆ°á»›c 4/4: LÆ°u graph...")

        graph_path = pipeline.save_graph(data)
        stats = pipeline.get_statistics()

        progress_bar.progress(100)
        status_text.text("âœ… HoÃ n táº¥t!")

        # LÆ°u stats vÃ o session state
        st.session_state['graph_stats'] = stats

        with log_container:
            st.success(f"""
            âœ… **XÃ‚Y Dá»°NG Máº NG LÆ¯á»šI HOÃ€N Táº¤T!**

            - Graph saved: `{graph_path}`
            - Node types: {data.node_types}
            - Edge types: {data.edge_types}

            Báº¡n cÃ³ thá»ƒ tiáº¿n hÃ nh **Huáº¥n luyá»‡n GNN** ngay bÃ¢y giá»!
            """)

        # Force rerun Ä‘á»ƒ update tráº¡ng thÃ¡i
        time.sleep(1)
        st.rerun()

    except Exception as e:
        progress_bar.progress(0)
        status_text.text("âŒ Lá»—i!")
        st.error(f"Lá»—i khi xÃ¢y dá»±ng graph: {str(e)}")
        import traceback
        st.code(traceback.format_exc())


def run_train_gnn(data_dir: str):
    """Cháº¡y quÃ¡ trÃ¬nh huáº¥n luyá»‡n GNN"""
    st.markdown("---")
    st.markdown("### ğŸ”„ Äang huáº¥n luyá»‡n GNN model...")

    progress_bar = st.progress(0)
    status_text = st.empty()
    log_container = st.container()

    try:
        import torch

        # Import modules
        from preprocessing.gnn_data_pipeline import GNNDataPipeline
        from models.layer2.gnn_hetero_model import GNNHeteroTrainer

        # BÆ°á»›c 1: Load graph
        status_text.text("ğŸ“ BÆ°á»›c 1/3: Load graph Ä‘Ã£ build...")
        progress_bar.progress(10)

        pipeline = GNNDataPipeline(data_dir, verbose=False)
        data = pipeline.load_graph()

        with log_container:
            st.success(f"âœ… Loaded graph: {len(data.node_types)} node types, {len(data.edge_types)} edge types")

        progress_bar.progress(20)

        # BÆ°á»›c 2: Train model
        status_text.text("ğŸ¤– BÆ°á»›c 2/3: Huáº¥n luyá»‡n model...")

        # Láº¥y config tá»« session state hoáº·c dÃ¹ng default
        model_config = st.session_state.get('gnn_config', config.GNN_CONFIG)

        trainer = GNNHeteroTrainer(model_config=model_config, verbose=False)

        # Training vá»›i progress updates
        train_results = trainer.fit(data)

        with log_container:
            st.success(f"âœ… Training completed: {train_results['epochs_trained']} epochs, Best AUC: {train_results['best_val_auc']:.4f}")

        progress_bar.progress(70)

        # BÆ°á»›c 3: Evaluate
        status_text.text("ğŸ“Š BÆ°á»›c 3/3: ÄÃ¡nh giÃ¡ model...")

        metrics = {}
        for split in ['train', 'val', 'test']:
            try:
                split_metrics = trainer.evaluate(data, mask_type=split)
                metrics[split] = split_metrics
            except:
                pass

        # Save model
        model_path = trainer.save()

        progress_bar.progress(100)
        status_text.text("âœ… HoÃ n táº¥t!")

        # LÆ°u results vÃ o session state
        st.session_state['gnn_results'] = {
            **metrics,
            'history': train_results['history'],
            'best_threshold': train_results['best_threshold']
        }

        with log_container:
            st.success(f"""
            âœ… **HUáº¤N LUYá»†N HOÃ€N Táº¤T!**

            - Model saved: `{model_path}`
            - Epochs trained: {train_results['epochs_trained']}
            - Best validation AUC: {train_results['best_val_auc']:.4f}
            - Optimal threshold: {train_results['best_threshold']:.4f}
            """)

            if 'test' in metrics:
                st.markdown("**Test Metrics:**")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Accuracy", f"{metrics['test']['accuracy']:.4f}")
                with col2:
                    st.metric("Precision", f"{metrics['test']['precision']:.4f}")
                with col3:
                    st.metric("Recall", f"{metrics['test']['recall']:.4f}")
                with col4:
                    st.metric("F1-Score", f"{metrics['test']['f1_score']:.4f}")

    except Exception as e:
        progress_bar.progress(0)
        status_text.text("âŒ Lá»—i!")
        st.error(f"Lá»—i khi huáº¥n luyá»‡n: {str(e)}")
        import traceback
        st.code(traceback.format_exc())


# ========== MAIN ==========
def main():
    """Main function"""
    page = render_sidebar()

    if page == "ğŸ  Tá»•ng quan":
        render_overview_page()
    elif page == "ğŸ¯ Layer 1":
        render_layer1_page()
    elif page == "ğŸ§  Layer 2":
        render_layer2_page()
    elif page == "ğŸ•¸ï¸ GNN Training":
        render_gnn_training_page()


if __name__ == "__main__":
    main()
