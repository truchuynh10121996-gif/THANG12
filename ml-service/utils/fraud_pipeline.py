"""
Fraud Detection Pipeline - Ph√¢n t√≠ch giao d·ªãch v·ªõi 5 models
============================================================
Pipeline chuy√™n nghi·ªáp ƒë·ªÉ ph√°t hi·ªán gian l·∫≠n/l·ª´a ƒë·∫£o.

5 Models ƒë∆∞·ª£c s·ª≠ d·ª•ng:
1. Isolation Forest - Ph√°t hi·ªán anomaly (Layer 1)
2. LightGBM - Supervised classification (Layer 1)
3. Autoencoder - Reconstruction error (Layer 2)
4. LSTM - Sequence analysis (Layer 2)
5. GNN - Graph neural network (Layer 2)

Quy tr√¨nh:
1. Nh·∫≠n d·ªØ li·ªáu giao d·ªãch ƒë√£ chu·∫©n b·ªã
2. Ch·∫°y qua t·ª´ng model
3. Ensemble k·∫øt qu·∫£
4. ƒê∆∞a ra quy·∫øt ƒë·ªãnh v√† gi·∫£i th√≠ch
"""

import os
import sys
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

logger = logging.getLogger('fraud_pipeline')

# Th√™m path ƒë·ªÉ import models
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class FraudDetectionPipeline:
    """
    Pipeline ph√°t hi·ªán gian l·∫≠n v·ªõi 5 models

    C√°c ng∆∞·ª°ng r·ªßi ro:
    - Low (Th·∫•p): < 0.3 - An to√†n, chuy·ªÉn ti·ªÅn th√†nh c√¥ng
    - Medium (Trung b√¨nh): 0.3 - 0.5 - C·∫ßn x√°c minh th√™m
    - High (Cao): 0.5 - 0.7 - Nghi ng·ªù cao, c·∫ßn ki·ªÉm tra
    - Critical (Nghi√™m tr·ªçng): > 0.7 - Ch·∫∑n giao d·ªãch
    """

    # Ng∆∞·ª°ng quy·∫øt ƒë·ªãnh
    THRESHOLD_LOW = 0.3
    THRESHOLD_MEDIUM = 0.5
    THRESHOLD_HIGH = 0.7

    # Tr·ªçng s·ªë cho t·ª´ng model
    MODEL_WEIGHTS = {
        'isolation_forest': 0.15,
        'lightgbm': 0.25,
        'autoencoder': 0.20,
        'lstm': 0.20,
        'gnn': 0.20
    }

    # Rule-based weights khi model ch∆∞a train
    RULE_WEIGHTS = {
        'amount_deviation': 0.25,      # ƒê·ªô l·ªách s·ªë ti·ªÅn
        'velocity': 0.20,              # T·∫ßn su·∫•t giao d·ªãch
        'time_pattern': 0.15,          # Th·ªùi gian giao d·ªãch
        'recipient_risk': 0.20,        # R·ªßi ro ng∆∞·ªùi nh·∫≠n
        'account_behavior': 0.20       # H√†nh vi t√†i kho·∫£n
    }

    def __init__(self):
        self.models = {}
        self.models_loaded = {
            'isolation_forest': False,
            'lightgbm': False,
            'autoencoder': False,
            'lstm': False,
            'gnn': False
        }
        self._load_models()

    def _load_models(self):
        """Load c√°c models ƒë√£ ƒë∆∞·ª£c train"""
        logger.info("Loading fraud detection models...")

        # Load Isolation Forest
        try:
            from models.layer1.isolation_forest import IsolationForestModel
            model = IsolationForestModel()
            if model.load():
                self.models['isolation_forest'] = model
                self.models_loaded['isolation_forest'] = True
                logger.info("‚úì Isolation Forest loaded")
        except Exception as e:
            logger.warning(f"Could not load Isolation Forest: {e}")

        # Load LightGBM
        try:
            from models.layer1.lightgbm_model import LightGBMModel
            model = LightGBMModel()
            if model.load():
                self.models['lightgbm'] = model
                self.models_loaded['lightgbm'] = True
                logger.info("‚úì LightGBM loaded")
        except Exception as e:
            logger.warning(f"Could not load LightGBM: {e}")

        # Load Autoencoder
        try:
            from models.layer2.autoencoder import AutoencoderModel
            model = AutoencoderModel()
            if model.load():
                self.models['autoencoder'] = model
                self.models_loaded['autoencoder'] = True
                logger.info("‚úì Autoencoder loaded")
        except Exception as e:
            logger.warning(f"Could not load Autoencoder: {e}")

        # Load LSTM
        try:
            from models.layer2.lstm_sequence import LSTMSequenceModel
            model = LSTMSequenceModel()
            if model.load():
                self.models['lstm'] = model
                self.models_loaded['lstm'] = True
                logger.info("‚úì LSTM loaded")
        except Exception as e:
            logger.warning(f"Could not load LSTM: {e}")

        # Load GNN
        try:
            from models.layer2.gnn_hetero_model import GNNHeteroModel
            model = GNNHeteroModel()
            if model.load():
                self.models['gnn'] = model
                self.models_loaded['gnn'] = True
                logger.info("‚úì GNN loaded")
        except Exception as e:
            logger.warning(f"Could not load GNN: {e}")

        loaded_count = sum(self.models_loaded.values())
        logger.info(f"Models loaded: {loaded_count}/5")

    def _calculate_rule_based_score(self, transaction_data: Dict) -> Tuple[float, Dict[str, float]]:
        """
        T√≠nh ƒëi·ªÉm r·ªßi ro d·ª±a tr√™n rules khi model ch∆∞a ƒë∆∞·ª£c train

        Ph∆∞∆°ng ph√°p n√†y ph√¢n t√≠ch c√°c ƒë·∫∑c tr∆∞ng giao d·ªãch v√† tr·∫£ v·ªÅ ƒëi·ªÉm r·ªßi ro
        c√≥ √Ω nghƒ©a thay v√¨ gi√° tr·ªã m·∫∑c ƒë·ªãnh 0.5

        Returns:
            Tuple[float, Dict]: (overall_score, component_scores)
        """
        component_scores = {}

        # 1. Amount Deviation Score (0-1)
        # S·ªë ti·ªÅn c√†ng l·ªách kh·ªèi trung b√¨nh, ƒëi·ªÉm r·ªßi ro c√†ng cao
        amount = transaction_data.get('amount', 0)
        avg_amount = transaction_data.get('avg_transaction_amount', 0)
        deviation_ratio = transaction_data.get('amount_deviation_ratio', 1)

        if avg_amount > 0:
            ratio = amount / avg_amount
            if ratio >= 5:
                amount_score = 0.9  # G·∫•p 5 l·∫ßn tr·ªü l√™n - r·∫•t r·ªßi ro
            elif ratio >= 3:
                amount_score = 0.7  # G·∫•p 3-5 l·∫ßn
            elif ratio >= 2:
                amount_score = 0.5  # G·∫•p 2-3 l·∫ßn
            elif ratio >= 1.5:
                amount_score = 0.3  # G·∫•p 1.5-2 l·∫ßn
            else:
                amount_score = 0.1  # B√¨nh th∆∞·ªùng
        else:
            # Kh√¥ng c√≥ l·ªãch s·ª≠, d√πng deviation ratio
            if deviation_ratio >= 3:
                amount_score = 0.7
            elif deviation_ratio >= 2:
                amount_score = 0.5
            else:
                amount_score = 0.2
        component_scores['amount_deviation'] = amount_score

        # 2. Velocity Score (0-1)
        # T·∫ßn su·∫•t giao d·ªãch cao = r·ªßi ro cao
        velocity_1h = transaction_data.get('velocity_1h', 0)
        velocity_24h = transaction_data.get('velocity_24h', 0)

        if velocity_1h >= 10:
            velocity_score = 0.95  # C·ª±c k·ª≥ b·∫•t th∆∞·ªùng
        elif velocity_1h >= 5:
            velocity_score = 0.8
        elif velocity_1h >= 3:
            velocity_score = 0.6
        elif velocity_24h >= 30:
            velocity_score = 0.7
        elif velocity_24h >= 20:
            velocity_score = 0.5
        elif velocity_24h >= 10:
            velocity_score = 0.3
        else:
            velocity_score = 0.1
        component_scores['velocity'] = velocity_score

        # 3. Time Pattern Score (0-1)
        # Giao d·ªãch ban ƒë√™m, ngo√†i gi·ªù l√†m vi·ªác = r·ªßi ro cao h∆°n
        is_night = transaction_data.get('is_night_transaction', 0)
        is_business_hours = transaction_data.get('is_during_business_hours', 0)
        hour = transaction_data.get('hour', 12)

        if is_night:
            if 2 <= hour <= 5:  # R·∫°ng s√°ng - r·∫•t b·∫•t th∆∞·ªùng
                time_score = 0.7
            else:
                time_score = 0.5
        elif not is_business_hours:
            time_score = 0.3
        else:
            time_score = 0.1
        component_scores['time_pattern'] = time_score

        # 4. Recipient Risk Score (0-1)
        # Ng∆∞·ªùi nh·∫≠n m·ªõi, ng√¢n h√†ng/v√≠ ƒëi·ªán t·ª≠ nh·ªè = r·ªßi ro cao
        is_new_recipient = transaction_data.get('is_new_recipient', 0)
        recipient_bank_risk = transaction_data.get('recipient_bank_risk', 1)
        is_unusual_account = transaction_data.get('is_unusual_account', 0)

        recipient_score = 0.1  # Base score
        if is_new_recipient:
            recipient_score += 0.3
        if recipient_bank_risk >= 2:  # V√≠ ƒëi·ªán t·ª≠ ho·∫∑c ng√¢n h√†ng nh·ªè
            recipient_score += 0.25
        elif recipient_bank_risk >= 1:
            recipient_score += 0.1
        if is_unusual_account:
            recipient_score += 0.25
        recipient_score = min(recipient_score, 1.0)
        component_scores['recipient_risk'] = recipient_score

        # 5. Account Behavior Score (0-1)
        # T√†i kho·∫£n m·ªõi, th·ªùi gian t·ª´ giao d·ªãch tr∆∞·ªõc = risk indicators
        account_age_days = transaction_data.get('account_age_days', 0)
        time_since_last = transaction_data.get('time_since_last_transaction', 0)

        behavior_score = 0.1
        if account_age_days < 30:
            behavior_score += 0.4  # T√†i kho·∫£n r·∫•t m·ªõi
        elif account_age_days < 90:
            behavior_score += 0.2  # T√†i kho·∫£n kh√° m·ªõi

        # Giao d·ªãch ƒë·ªôt ng·ªôt sau th·ªùi gian d√†i kh√¥ng ho·∫°t ƒë·ªông
        if time_since_last > 30 * 24 * 60:  # > 30 ng√†y (t√≠nh theo ph√∫t)
            behavior_score += 0.3
        elif time_since_last > 7 * 24 * 60:  # > 7 ng√†y
            behavior_score += 0.15

        behavior_score = min(behavior_score, 1.0)
        component_scores['account_behavior'] = behavior_score

        # T√≠nh overall score v·ªõi weighted average
        overall_score = sum(
            score * self.RULE_WEIGHTS[component]
            for component, score in component_scores.items()
        )

        return overall_score, component_scores

    def _prepare_features(self, transaction_data: Dict) -> np.ndarray:
        """Chu·∫©n b·ªã features vector t·ª´ transaction data"""
        # Features c∆° b·∫£n cho Isolation Forest v√† LightGBM
        features = [
            transaction_data.get('amount', 0),
            transaction_data.get('amount_log', 0),
            transaction_data.get('hour', 12),
            transaction_data.get('day_of_week', 0),
            transaction_data.get('velocity_1h', 0),
            transaction_data.get('velocity_24h', 0),
            transaction_data.get('time_since_last_transaction', 0),
            transaction_data.get('amount_deviation_ratio', 1),
            transaction_data.get('is_night_transaction', 0),
            transaction_data.get('is_during_business_hours', 0),
            transaction_data.get('is_new_recipient', 0),
            transaction_data.get('channel_encoded', 0),
            transaction_data.get('transaction_type_encoded', 0),
            transaction_data.get('account_age_days', 0),
            transaction_data.get('amount_to_avg_ratio', 1),
            transaction_data.get('is_international', 0),
            # Recipient features m·ªõi
            transaction_data.get('recipient_bank_risk', 1),
            transaction_data.get('is_unusual_account', 0),
        ]
        return np.array(features).reshape(1, -1)

    def _run_isolation_forest(self, features: np.ndarray) -> Tuple[float, Dict]:
        """Ch·∫°y Isolation Forest model"""
        if not self.models_loaded['isolation_forest']:
            return 0.5, {'loaded': False, 'reason': 'Model not loaded'}

        try:
            model = self.models['isolation_forest']
            score = model.predict_proba(features)[0]
            anomaly_score = model.get_anomaly_score(features)[0]

            return float(score), {
                'loaded': True,
                'fraud_probability': float(score),
                'anomaly_score': float(anomaly_score),
                'description': 'Ph√°t hi·ªán b·∫•t th∆∞·ªùng d·ª±a tr√™n ph√¢n b·ªë d·ªØ li·ªáu'
            }
        except Exception as e:
            logger.error(f"Isolation Forest error: {e}")
            return 0.5, {'loaded': True, 'error': str(e)}

    def _run_lightgbm(self, features: np.ndarray) -> Tuple[float, Dict]:
        """Ch·∫°y LightGBM model"""
        if not self.models_loaded['lightgbm']:
            return 0.5, {'loaded': False, 'reason': 'Model not loaded'}

        try:
            model = self.models['lightgbm']
            proba = model.predict_proba(features)[0]
            prediction = model.predict(features)[0]

            return float(proba), {
                'loaded': True,
                'fraud_probability': float(proba),
                'prediction': int(prediction),
                'description': 'Ph√¢n lo·∫°i d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng giao d·ªãch'
            }
        except Exception as e:
            logger.error(f"LightGBM error: {e}")
            return 0.5, {'loaded': True, 'error': str(e)}

    def _run_autoencoder(self, features: np.ndarray) -> Tuple[float, Dict]:
        """Ch·∫°y Autoencoder model"""
        if not self.models_loaded['autoencoder']:
            return 0.5, {'loaded': False, 'reason': 'Model not loaded'}

        try:
            model = self.models['autoencoder']
            recon_error = model.get_reconstruction_error(features)[0]
            proba = model.predict_proba(features)[0]

            return float(proba), {
                'loaded': True,
                'fraud_probability': float(proba),
                'reconstruction_error': float(recon_error),
                'threshold': float(model.threshold) if model.threshold else 0,
                'description': 'Ph√°t hi·ªán b·∫•t th∆∞·ªùng d·ª±a tr√™n l·ªói t√°i t·∫°o'
            }
        except Exception as e:
            logger.error(f"Autoencoder error: {e}")
            return 0.5, {'loaded': True, 'error': str(e)}

    def _run_lstm(self, transaction_data: Dict, features: np.ndarray) -> Tuple[float, Dict]:
        """Ch·∫°y LSTM model"""
        if not self.models_loaded['lstm']:
            return 0.5, {'loaded': False, 'reason': 'Model not loaded'}

        try:
            model = self.models['lstm']

            # LSTM c·∫ßn sequence, n·∫øu ch·ªâ c√≥ 1 giao d·ªãch th√¨ t·∫°o dummy sequence
            # Trong th·ª±c t·∫ø, c·∫ßn l·∫•y l·ªãch s·ª≠ giao d·ªãch ƒë·ªÉ t·∫°o sequence ƒë·∫ßy ƒë·ªß
            seq_length = model.seq_length if hasattr(model, 'seq_length') else 7
            num_features = features.shape[1]

            # T·∫°o sequence v·ªõi padding
            sequence = np.zeros((1, seq_length, num_features))
            sequence[0, -1, :] = features[0]  # Giao d·ªãch hi·ªán t·∫°i ·ªü cu·ªëi

            proba = model.predict_proba(sequence)[0]

            return float(proba), {
                'loaded': True,
                'fraud_probability': float(proba),
                'seq_length': seq_length,
                'description': 'Ph√¢n t√≠ch chu·ªói giao d·ªãch theo th·ªùi gian'
            }
        except Exception as e:
            logger.error(f"LSTM error: {e}")
            return 0.5, {'loaded': True, 'error': str(e)}

    def _run_gnn(self, transaction_data: Dict) -> Tuple[float, Dict]:
        """Ch·∫°y GNN model"""
        if not self.models_loaded['gnn']:
            return 0.5, {'loaded': False, 'reason': 'Model not loaded'}

        try:
            model = self.models['gnn']
            # GNN c·∫ßn graph structure, ƒë√¢y l√† simplified version
            proba = 0.5  # Default n·∫øu kh√¥ng c√≥ graph

            return float(proba), {
                'loaded': True,
                'fraud_probability': float(proba),
                'description': 'Ph√¢n t√≠ch m·ªëi quan h·ªá trong m·∫°ng l∆∞·ªõi giao d·ªãch'
            }
        except Exception as e:
            logger.error(f"GNN error: {e}")
            return 0.5, {'loaded': True, 'error': str(e)}

    def _ensemble_predictions(self, model_scores: Dict[str, float]) -> float:
        """
        K·∫øt h·ª£p k·∫øt qu·∫£ t·ª´ c√°c models

        Args:
            model_scores: Dict v·ªõi t√™n model v√† ƒëi·ªÉm s·ªë

        Returns:
            float: ƒêi·ªÉm r·ªßi ro t·ªïng h·ª£p (0-1)
        """
        total_weight = 0
        weighted_sum = 0

        for model_name, score in model_scores.items():
            weight = self.MODEL_WEIGHTS.get(model_name, 0)
            if self.models_loaded.get(model_name, False):
                weighted_sum += score * weight
                total_weight += weight

        if total_weight == 0:
            # Fallback: d√πng rule-based n·∫øu kh√¥ng c√≥ model n√†o
            return 0.5

        return weighted_sum / total_weight

    def _determine_risk_level(self, fraud_probability: float) -> str:
        """X√°c ƒë·ªãnh m·ª©c ƒë·ªô r·ªßi ro"""
        if fraud_probability >= self.THRESHOLD_HIGH:
            return 'critical'
        elif fraud_probability >= self.THRESHOLD_MEDIUM:
            return 'high'
        elif fraud_probability >= self.THRESHOLD_LOW:
            return 'medium'
        else:
            return 'low'

    def _generate_explanation(
        self,
        transaction_data: Dict,
        model_results: Dict,
        risk_level: str
    ) -> Dict[str, Any]:
        """
        T·∫°o gi·∫£i th√≠ch chi ti·∫øt v·ªÅ quy·∫øt ƒë·ªãnh

        Returns:
            Dict ch·ª©a summary, risk_factors, v√† recommendations
        """
        risk_factors = []
        recommendations = []
        positive_factors = []

        amount = transaction_data.get('amount', 0)
        avg_amount = transaction_data.get('avg_transaction_amount', 0)
        deviation = transaction_data.get('amount_deviation_ratio', 1)
        velocity_1h = transaction_data.get('velocity_1h', 0)
        velocity_24h = transaction_data.get('velocity_24h', 0)
        is_night = transaction_data.get('is_night_transaction', 0)
        is_new_recipient = transaction_data.get('is_new_recipient', 0)
        is_international = transaction_data.get('is_international', 0)

        # Ph√¢n t√≠ch s·ªë ti·ªÅn
        if avg_amount > 0 and amount > avg_amount * 3:
            risk_factors.append({
                'factor': f'S·ªë ti·ªÅn ({amount:,.0f}ƒë) cao g·∫•p {amount/avg_amount:.1f}x so v·ªõi trung b√¨nh ({avg_amount:,.0f}ƒë)',
                'importance': 'high'
            })
            recommendations.append('X√°c nh·∫≠n l·∫°i v·ªõi kh√°ch h√†ng qua OTP ho·∫∑c cu·ªôc g·ªçi')
        elif avg_amount > 0 and amount > avg_amount * 2:
            risk_factors.append({
                'factor': f'S·ªë ti·ªÅn cao h∆°n trung b√¨nh ({amount:,.0f}ƒë vs {avg_amount:,.0f}ƒë)',
                'importance': 'medium'
            })

        # Ph√¢n t√≠ch ƒë·ªô l·ªách
        if deviation > 3:
            risk_factors.append({
                'factor': f'ƒê·ªô l·ªách s·ªë ti·ªÅn cao (x{deviation})',
                'importance': 'high'
            })

        # Ph√¢n t√≠ch velocity
        if velocity_1h >= 5:
            risk_factors.append({
                'factor': f'T·∫ßn su·∫•t giao d·ªãch cao b·∫•t th∆∞·ªùng ({velocity_1h} GD/gi·ªù)',
                'importance': 'high'
            })
            recommendations.append('Ki·ªÉm tra xem t√†i kho·∫£n c√≥ b·ªã chi·∫øm ƒëo·∫°t kh√¥ng')
        elif velocity_24h >= 20:
            risk_factors.append({
                'factor': f'S·ªë giao d·ªãch trong 24h cao ({velocity_24h} GD)',
                'importance': 'medium'
            })

        # Ph√¢n t√≠ch th·ªùi gian
        if is_night:
            risk_factors.append({
                'factor': 'Giao d·ªãch v√†o ban ƒë√™m (22h-6h)',
                'importance': 'medium'
            })

        # Ph√¢n t√≠ch ng∆∞·ªùi nh·∫≠n (v·ªõi th√¥ng tin chi ti·∫øt t·ª´ form m·ªõi)
        recipient_info = transaction_data.get('_recipient_info', {})
        recipient_name = recipient_info.get('name') or transaction_data.get('recipient_name', '')
        recipient_bank = recipient_info.get('bank') or transaction_data.get('recipient_bank', '')
        recipient_bank_risk = transaction_data.get('recipient_bank_risk', 1)
        is_unusual_account = transaction_data.get('is_unusual_account', 0)

        if is_new_recipient:
            if recipient_name:
                risk_factors.append({
                    'factor': f'Ng∆∞·ªùi nh·∫≠n "{recipient_name}" l√† ƒë·ªëi t√°c m·ªõi (ch∆∞a giao d·ªãch tr∆∞·ªõc ƒë√≥)',
                    'importance': 'medium'
                })
            else:
                risk_factors.append({
                    'factor': 'Ng∆∞·ªùi nh·∫≠n l√† ƒë·ªëi t√°c m·ªõi',
                    'importance': 'medium'
                })
            recommendations.append('X√°c minh th√¥ng tin ng∆∞·ªùi nh·∫≠n tr∆∞·ªõc khi chuy·ªÉn ti·ªÅn')

        # Ki·ªÉm tra ng√¢n h√†ng/v√≠ ƒëi·ªán t·ª≠
        if recipient_bank_risk >= 2:
            bank_name = recipient_bank or 'v√≠ ƒëi·ªán t·ª≠/ng√¢n h√†ng nh·ªè'
            risk_factors.append({
                'factor': f'Chuy·ªÉn ti·ªÅn ƒë·∫øn {bank_name} - c·∫ßn x√°c minh k·ªπ h∆°n',
                'importance': 'medium'
            })

        # Ki·ªÉm tra s·ªë t√†i kho·∫£n b·∫•t th∆∞·ªùng
        if is_unusual_account:
            risk_factors.append({
                'factor': 'S·ªë t√†i kho·∫£n c√≥ ƒë·ªãnh d·∫°ng kh√¥ng b√¨nh th∆∞·ªùng',
                'importance': 'medium'
            })
            recommendations.append('Ki·ªÉm tra l·∫°i s·ªë t√†i kho·∫£n ng∆∞·ªùi nh·∫≠n')

        # Giao d·ªãch qu·ªëc t·∫ø
        if is_international:
            risk_factors.append({
                'factor': 'Giao d·ªãch qu·ªëc t·∫ø',
                'importance': 'medium'
            })
            recommendations.append('X√°c nh·∫≠n danh t√≠nh v√† m·ª•c ƒë√≠ch giao d·ªãch')

        # Ph√¢n t√≠ch k·∫øt qu·∫£ models
        for model_name, result in model_results.items():
            if isinstance(result, dict) and result.get('loaded'):
                prob = result.get('fraud_probability', 0.5)
                if prob > 0.7:
                    risk_factors.append({
                        'factor': f'Model {model_name}: Ph√°t hi·ªán r·ªßi ro cao ({prob*100:.0f}%)',
                        'importance': 'high'
                    })
                elif prob > 0.5:
                    risk_factors.append({
                        'factor': f'Model {model_name}: Ph√°t hi·ªán r·ªßi ro ({prob*100:.0f}%)',
                        'importance': 'medium'
                    })

        # C√°c y·∫øu t·ªë t√≠ch c·ª±c
        if len(risk_factors) == 0:
            positive_factors.append('S·ªë ti·ªÅn giao d·ªãch n·∫±m trong ph·∫°m vi b√¨nh th∆∞·ªùng')
            positive_factors.append('Kh√¥ng ph√°t hi·ªán b·∫•t th∆∞·ªùng v·ªÅ h√†nh vi')

        account_age = transaction_data.get('account_age_days', 0)
        if account_age > 365:
            positive_factors.append(f'T√†i kho·∫£n l√¢u nƒÉm ({account_age} ng√†y)')

        # T·∫°o summary
        if risk_level == 'critical':
            summary = f"‚ö†Ô∏è C·∫¢NH B√ÅO: Giao d·ªãch c√≥ {len(risk_factors)} y·∫øu t·ªë r·ªßi ro nghi√™m tr·ªçng. Khuy·∫øn ngh·ªã CH·∫∂N giao d·ªãch."
            recommendations.insert(0, 'üõë Ch·∫∑n giao d·ªãch ngay l·∫≠p t·ª©c')
            recommendations.append('Li√™n h·ªá kh√°ch h√†ng ƒë·ªÉ x√°c minh')
        elif risk_level == 'high':
            summary = f"‚ö†Ô∏è NGHI NG·ªú: Giao d·ªãch c√≥ {len(risk_factors)} y·∫øu t·ªë r·ªßi ro. C·∫ßn xem x√©t k·ªπ tr∆∞·ªõc khi duy·ªát."
            recommendations.insert(0, '‚è∏Ô∏è T·∫°m gi·ªØ giao d·ªãch ƒë·ªÉ x√°c minh')
        elif risk_level == 'medium':
            summary = f"‚ö° Giao d·ªãch c√≥ {len(risk_factors)} y·∫øu t·ªë c·∫ßn l∆∞u √Ω. C√≥ th·ªÉ cho ph√©p v·ªõi x√°c th·ª±c b·ªï sung."
            if 'X√°c nh·∫≠n OTP' not in recommendations:
                recommendations.append('Y√™u c·∫ßu x√°c nh·∫≠n OTP')
        else:
            summary = f"‚úÖ Giao d·ªãch AN TO√ÄN. Kh√¥ng ph√°t hi·ªán d·∫•u hi·ªáu b·∫•t th∆∞·ªùng."
            recommendations = ['Cho ph√©p giao d·ªãch']

        return {
            'summary': summary,
            'risk_factors': risk_factors,
            'positive_factors': positive_factors,
            'recommendations': recommendations
        }

    def analyze_transaction(self, transaction_data: Dict) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch giao d·ªãch v√† ƒë∆∞a ra quy·∫øt ƒë·ªãnh

        Args:
            transaction_data: D·ªØ li·ªáu giao d·ªãch ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß
        """
        logger.info(f"Analyzing transaction: {transaction_data.get('transaction_id')}")

        # Ki·ªÉm tra xem c√≥ model n√†o ƒë∆∞·ª£c load kh√¥ng
        models_loaded_count = sum(self.models_loaded.values())
        use_rule_based = models_loaded_count == 0

        # Chu·∫©n b·ªã features
        features = self._prepare_features(transaction_data)

        # Ch·∫°y t·ª´ng model
        model_results = {}
        model_scores = {}

        if use_rule_based:
            # S·ª≠ d·ª•ng Rule-Based Scoring khi ch∆∞a train model
            logger.info("No ML models loaded. Using rule-based scoring...")
            rule_score, component_scores = self._calculate_rule_based_score(transaction_data)

            # T·∫°o k·∫øt qu·∫£ cho t·ª´ng "model" ·∫£o d·ª±a tr√™n rule components
            model_scores = {
                'isolation_forest': component_scores.get('amount_deviation', 0.5),
                'lightgbm': component_scores.get('account_behavior', 0.5),
                'autoencoder': component_scores.get('velocity', 0.5),
                'lstm': component_scores.get('time_pattern', 0.5),
                'gnn': component_scores.get('recipient_risk', 0.5)
            }

            model_results = {
                'isolation_forest': {
                    'loaded': False,
                    'mode': 'rule_based',
                    'component': 'amount_deviation',
                    'fraud_probability': component_scores.get('amount_deviation', 0.5),
                    'description': 'Ph√¢n t√≠ch ƒë·ªô l·ªách s·ªë ti·ªÅn (Rule-Based)'
                },
                'lightgbm': {
                    'loaded': False,
                    'mode': 'rule_based',
                    'component': 'account_behavior',
                    'fraud_probability': component_scores.get('account_behavior', 0.5),
                    'description': 'Ph√¢n t√≠ch h√†nh vi t√†i kho·∫£n (Rule-Based)'
                },
                'autoencoder': {
                    'loaded': False,
                    'mode': 'rule_based',
                    'component': 'velocity',
                    'fraud_probability': component_scores.get('velocity', 0.5),
                    'description': 'Ph√¢n t√≠ch t·∫ßn su·∫•t giao d·ªãch (Rule-Based)'
                },
                'lstm': {
                    'loaded': False,
                    'mode': 'rule_based',
                    'component': 'time_pattern',
                    'fraud_probability': component_scores.get('time_pattern', 0.5),
                    'description': 'Ph√¢n t√≠ch th·ªùi gian giao d·ªãch (Rule-Based)'
                },
                'gnn': {
                    'loaded': False,
                    'mode': 'rule_based',
                    'component': 'recipient_risk',
                    'fraud_probability': component_scores.get('recipient_risk', 0.5),
                    'description': 'Ph√¢n t√≠ch r·ªßi ro ng∆∞·ªùi nh·∫≠n (Rule-Based)'
                }
            }

            fraud_probability = rule_score
        else:
            # S·ª≠ d·ª•ng ML Models
            # Isolation Forest
            score, result = self._run_isolation_forest(features)
            model_results['isolation_forest'] = result
            model_scores['isolation_forest'] = score

            # LightGBM
            score, result = self._run_lightgbm(features)
            model_results['lightgbm'] = result
            model_scores['lightgbm'] = score

            # Autoencoder
            score, result = self._run_autoencoder(features)
            model_results['autoencoder'] = result
            model_scores['autoencoder'] = score

            # LSTM
            score, result = self._run_lstm(transaction_data, features)
            model_results['lstm'] = result
            model_scores['lstm'] = score

            # GNN
            score, result = self._run_gnn(transaction_data)
            model_results['gnn'] = result
            model_scores['gnn'] = score

            # Ensemble
            fraud_probability = self._ensemble_predictions(model_scores)

        # X√°c ƒë·ªãnh risk level
        risk_level = self._determine_risk_level(fraud_probability)

        # Quy·∫øt ƒë·ªãnh
        should_block = risk_level in ['critical', 'high']
        prediction = 'fraud' if fraud_probability >= self.THRESHOLD_MEDIUM else 'normal'

        # T√≠nh confidence
        scores = list(model_scores.values())
        confidence = 1 - np.std(scores) if len(scores) > 1 else 0.5

        # T·∫°o gi·∫£i th√≠ch
        explanation = self._generate_explanation(transaction_data, model_results, risk_level)

        # Th√™m th√¥ng tin v·ªÅ mode ƒëang s·ª≠ d·ª•ng
        analysis_mode = 'rule_based' if use_rule_based else 'ml_models'

        return {
            'transaction_id': transaction_data.get('transaction_id'),
            'user_id': transaction_data.get('user_id'),
            'amount': transaction_data.get('amount'),
            'analysis_mode': analysis_mode,
            'models_loaded_count': models_loaded_count,
            'prediction': {
                'fraud_probability': round(fraud_probability, 4),
                'prediction': prediction,
                'risk_level': risk_level,
                'should_block': should_block,
                'confidence': round(confidence, 2)
            },
            'model_scores': {
                model: round(score, 4) for model, score in model_scores.items()
            },
            'model_details': model_results,
            'models_status': self.models_loaded,
            'explanation': explanation,
            'behavioral_features': transaction_data.get('_behavioral_features'),
            'timestamp': datetime.now().isoformat()
        }


# Singleton instance
_pipeline = None


def get_fraud_pipeline() -> FraudDetectionPipeline:
    """L·∫•y instance c·ªßa FraudDetectionPipeline (singleton)"""
    global _pipeline
    if _pipeline is None:
        _pipeline = FraudDetectionPipeline()
    return _pipeline
