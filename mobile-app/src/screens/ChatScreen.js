import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  StyleSheet,
  KeyboardAvoidingView,
  Platform,
  ScrollView,
  ActivityIndicator,
  Alert,
  Modal,
  Image
} from 'react-native';
import { LinearGradient } from 'expo-linear-gradient';
import { Ionicons } from '@expo/vector-icons';
import * as ImagePicker from 'expo-image-picker';
import ChatBubble from '../components/ChatBubble';
import VoiceRecorder from '../components/VoiceRecorder';
import { sendMessage, synthesizeSpeech, analyzeImage } from '../services/api';

export default function ChatScreen({ route, navigation }) {
  const { language = 'vi' } = route.params || {};

  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [conversationId, setConversationId] = useState(null);

  // Image states
  const [selectedImage, setSelectedImage] = useState(null);
  const [showImageModal, setShowImageModal] = useState(false);
  const [isAnalyzingImage, setIsAnalyzingImage] = useState(false);

  const scrollViewRef = useRef();

  useEffect(() => {
    // Tin nh·∫Øn ch√†o m·ª´ng
    const welcomeMessage = getWelcomeMessage(language);
    setMessages([
      {
        id: '1',
        text: welcomeMessage,
        sender: 'bot',
        timestamp: new Date()
      }
    ]);
  }, []);

  const getWelcomeMessage = (lang) => {
    const messages = {
      vi: `Xin ch√†o! üëã\n\nT√¥i l√† Agribank Digital Guard, tr·ª£ l√Ω AI chuy√™n v·ªÅ ph√≤ng ch·ªëng l·ª´a ƒë·∫£o.\n\nN·∫øu b·∫°n g·∫∑p b·∫•t k·ª≥ t√¨nh hu·ªëng ƒë√°ng ng·ªù n√†o, h√£y m√¥ t·∫£ cho t√¥i. T√¥i s·∫Ω ph√¢n t√≠ch v√† ƒë∆∞a ra c·∫£nh b√°o c√πng h∆∞·ªõng d·∫´n x·ª≠ l√Ω an to√†n.\n\nB·∫°n c√≥ th·ªÉ nh·∫≠p vƒÉn b·∫£n ho·∫∑c d√πng n√∫t üé§ ƒë·ªÉ ghi √¢m gi·ªçng n√≥i.`,
      en: `Hello! üëã\n\nI am Agribank Digital Guard, an AI assistant specializing in fraud prevention.\n\nIf you encounter any suspicious situations, please describe them to me. I will analyze and provide warnings along with safe handling instructions.\n\nYou can type text or use the üé§ button to record your voice.`,
      km: `·ûü·ûΩ·ûü·üí·ûè·û∏! üëã\n\n·ûÅ·üí·ûâ·ûª·üÜ·ûÇ·û∫ Agribank Digital Guard ·ûá·üÜ·ûì·ûΩ·ûô·ûÄ·û∂·ûö AI ·ûØ·ûÄ·ûë·üÅ·ûü·ûÅ·û∂·ûÑ·ûÄ·û∂·ûö·ûñ·û∂·ûö·ûÄ·û∂·ûö·ûõ·ûΩ·ûÖ·ûî·ûì·üí·ûõ·üÜ·üî\n\n·ûî·üí·ûö·ûü·û∑·ûì·ûî·ûæ·û¢·üí·ûì·ûÄ·ûá·ûΩ·ûî·ûü·üí·ûê·û∂·ûì·ûó·û∂·ûñ·ûü·ûÑ·üí·ûü·üê·ûô ·ûü·ûº·ûò·ûñ·ûé·üå·ûì·û∂·ûä·ûõ·üã·ûÅ·üí·ûâ·ûª·üÜ·üî ·ûÅ·üí·ûâ·ûª·üÜ·ûì·ûπ·ûÑ·ûú·û∑·ûó·û∂·ûÇ ·ûì·û∑·ûÑ·ûï·üí·ûè·ûõ·üã·ûÄ·û∂·ûö·ûñ·üí·ûö·ûò·û∂·ûì ·ûö·ûΩ·ûò·ûá·û∂·ûò·ûΩ·ûô·ûÄ·û∂·ûö·ûé·üÇ·ûì·û∂·üÜ·ûü·ûª·ûú·ûè·üí·ûê·û∑·ûó·û∂·ûñ·üî\n\n·û¢·üí·ûì·ûÄ·û¢·û∂·ûÖ·ûú·û∂·ûô·û¢·ûÄ·üí·ûü·ûö ·û¨·ûî·üí·ûö·ûæ·ûî·üä·ûº·ûè·ûª·ûÑ üé§ ·ûä·ûæ·ûò·üí·ûî·û∏·ûê·ûè·ûü·üÜ·û°·üÅ·ûÑ·üî`
    };
    return messages[lang] || messages.vi;
  };

  const handleSendMessage = async () => {
    if (!inputText.trim()) return;

    const userMessage = {
      id: Date.now().toString(),
      text: inputText,
      sender: 'user',
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsLoading(true);

    try {
      const response = await sendMessage({
        message: inputText,
        conversationId,
        language
      });

      if (!conversationId) {
        setConversationId(response.conversationId);
      }

      const botMessage = {
        id: (Date.now() + 1).toString(),
        text: response.response,
        sender: 'bot',
        timestamp: new Date(),
        isFraudAlert: response.isFraudAlert,
        audioData: null // Will be loaded on demand
      };

      setMessages(prev => [...prev, botMessage]);

    } catch (error) {
      console.error('Send message error:', error);
      Alert.alert('L·ªói', 'Kh√¥ng th·ªÉ g·ª≠i tin nh·∫Øn. Vui l√≤ng th·ª≠ l·∫°i.');

      const errorMessage = {
        id: (Date.now() + 1).toString(),
        text: 'Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·∫øt n·ªëi. Vui l√≤ng th·ª≠ l·∫°i sau.',
        sender: 'bot',
        timestamp: new Date()
      };

      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleVoiceRecorded = (transcription) => {
    if (transcription) {
      setInputText(transcription);
    }
  };

  // Image picker handlers
  const handlePickImage = async () => {
    // Request permission
    const { status } = await ImagePicker.requestMediaLibraryPermissionsAsync();
    if (status !== 'granted') {
      Alert.alert(
        language === 'vi' ? 'C·∫ßn quy·ªÅn truy c·∫≠p' : 'Permission Required',
        language === 'vi'
          ? 'Vui l√≤ng c·∫•p quy·ªÅn truy c·∫≠p th∆∞ vi·ªán ·∫£nh ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.'
          : 'Please grant photo library access to use this feature.'
      );
      return;
    }

    const result = await ImagePicker.launchImageLibraryAsync({
      mediaTypes: ImagePicker.MediaTypeOptions.Images,
      allowsEditing: false,
      quality: 0.8,
      base64: true
    });

    if (!result.canceled && result.assets[0]) {
      setSelectedImage(result.assets[0]);
      setShowImageModal(true);
    }
  };

  const handleTakePhoto = async () => {
    // Request permission
    const { status } = await ImagePicker.requestCameraPermissionsAsync();
    if (status !== 'granted') {
      Alert.alert(
        language === 'vi' ? 'C·∫ßn quy·ªÅn truy c·∫≠p' : 'Permission Required',
        language === 'vi'
          ? 'Vui l√≤ng c·∫•p quy·ªÅn truy c·∫≠p camera ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.'
          : 'Please grant camera access to use this feature.'
      );
      return;
    }

    const result = await ImagePicker.launchCameraAsync({
      allowsEditing: false,
      quality: 0.8,
      base64: true
    });

    if (!result.canceled && result.assets[0]) {
      setSelectedImage(result.assets[0]);
      setShowImageModal(true);
    }
  };

  const handleImageOptions = () => {
    Alert.alert(
      language === 'vi' ? 'Ch·ªçn ·∫£nh' : 'Select Image',
      language === 'vi'
        ? 'Ch·ªçn c√°ch l·∫•y ·∫£nh tin nh·∫Øn ƒë·ªÉ ki·ªÉm tra l·ª´a ƒë·∫£o'
        : 'Choose how to get the message screenshot to check for fraud',
      [
        {
          text: language === 'vi' ? 'Ch·ª•p ·∫£nh' : 'Take Photo',
          onPress: handleTakePhoto
        },
        {
          text: language === 'vi' ? 'Ch·ªçn t·ª´ th∆∞ vi·ªán' : 'Choose from Library',
          onPress: handlePickImage
        },
        {
          text: language === 'vi' ? 'H·ªßy' : 'Cancel',
          style: 'cancel'
        }
      ]
    );
  };

  const handleAnalyzeImage = async () => {
    if (!selectedImage || !selectedImage.base64) {
      Alert.alert('Error', 'No image selected');
      return;
    }

    setShowImageModal(false);
    setIsAnalyzingImage(true);

    // Add user message with image
    const userMessage = {
      id: Date.now().toString(),
      text: language === 'vi' ? '[·∫¢nh ch·ª•p m√†n h√¨nh]' : '[Screenshot]',
      sender: 'user',
      timestamp: new Date(),
      hasImage: true,
      imageUri: selectedImage.uri
    };

    setMessages(prev => [...prev, userMessage]);

    try {
      const imageBase64 = `data:image/jpeg;base64,${selectedImage.base64}`;

      const response = await analyzeImage({
        imageBase64,
        conversationId,
        language
      });

      if (!conversationId && response.conversationId) {
        setConversationId(response.conversationId);
      }

      const botMessage = {
        id: (Date.now() + 1).toString(),
        text: response.response,
        sender: 'bot',
        timestamp: new Date(),
        isFraudAlert: response.isFraudAlert,
        ocrResult: response.ocrResult
      };

      setMessages(prev => [...prev, botMessage]);

      if (response.isFraudAlert) {
        Alert.alert(
          language === 'vi' ? '‚ö†Ô∏è C·∫£nh b√°o l·ª´a ƒë·∫£o!' : '‚ö†Ô∏è Fraud Alert!',
          language === 'vi'
            ? 'Ph√°t hi·ªán d·∫•u hi·ªáu l·ª´a ƒë·∫£o trong ·∫£nh. Vui l√≤ng ƒë·ªçc ph√¢n t√≠ch chi ti·∫øt.'
            : 'Fraud indicators detected in the image. Please read the detailed analysis.'
        );
      }

    } catch (error) {
      console.error('Analyze image error:', error);
      Alert.alert(
        language === 'vi' ? 'L·ªói' : 'Error',
        language === 'vi'
          ? 'Kh√¥ng th·ªÉ ph√¢n t√≠ch ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.'
          : 'Cannot analyze image. Please try again.'
      );

      const errorMessage = {
        id: (Date.now() + 1).toString(),
        text: language === 'vi'
          ? 'Xin l·ªói, t√¥i kh√¥ng th·ªÉ ph√¢n t√≠ch ·∫£nh n√†y. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c m√¥ t·∫£ n·ªôi dung tin nh·∫Øn b·∫±ng vƒÉn b·∫£n.'
          : 'Sorry, I cannot analyze this image. Please try again or describe the message content in text.',
        sender: 'bot',
        timestamp: new Date()
      };

      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsAnalyzingImage(false);
      setSelectedImage(null);
    }
  };

  const scrollToBottom = () => {
    setTimeout(() => {
      scrollViewRef.current?.scrollToEnd({ animated: true });
    }, 100);
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  return (
    <LinearGradient
      colors={['#FBD6E3', '#A9EDE9']}
      style={styles.container}
      start={{ x: 0, y: 0 }}
      end={{ x: 1, y: 1 }}
    >
      <KeyboardAvoidingView
        style={styles.container}
        behavior={Platform.OS === 'ios' ? 'padding' : 'height'}
        keyboardVerticalOffset={Platform.OS === 'ios' ? 0 : 20}
      >
        {/* Header */}
        <View style={styles.header}>
          <TouchableOpacity
            onPress={() => navigation.goBack()}
            style={styles.backButton}
          >
            <Ionicons name="arrow-back" size={24} color="#FF8DAD" />
          </TouchableOpacity>

          <View style={styles.headerTitleContainer}>
            <Text style={styles.headerTitle}>Digital Guard</Text>
            <Text style={styles.headerSubtitle}>üõ°Ô∏è AI Assistant</Text>
          </View>

          <TouchableOpacity style={styles.infoButton}>
            <Ionicons name="information-circle" size={24} color="#FF8DAD" />
          </TouchableOpacity>
        </View>

        {/* Messages */}
        <ScrollView
          ref={scrollViewRef}
          style={styles.messagesContainer}
          contentContainerStyle={styles.messagesContent}
          showsVerticalScrollIndicator={false}
        >
          {messages.map((message) => (
            <ChatBubble
              key={message.id}
              message={message}
              language={language}
            />
          ))}

          {(isLoading || isAnalyzingImage) && (
            <View style={styles.loadingContainer}>
              <ActivityIndicator size="small" color="#FF8DAD" />
              <Text style={styles.loadingText}>
                {isAnalyzingImage
                  ? (language === 'vi' ? 'ƒêang ph√¢n t√≠ch ·∫£nh...' : 'Analyzing image...')
                  : (language === 'vi' ? 'ƒêang suy nghƒ©...' : 'Thinking...')
                }
              </Text>
            </View>
          )}
        </ScrollView>

        {/* Input */}
        <View style={styles.inputContainer}>
          <View style={styles.inputWrapper}>
            {/* Camera/Image Button */}
            <TouchableOpacity
              style={styles.cameraButton}
              onPress={handleImageOptions}
              disabled={isLoading || isAnalyzingImage}
            >
              <Ionicons
                name="camera"
                size={24}
                color={isLoading || isAnalyzingImage ? '#CCC' : '#FF8DAD'}
              />
            </TouchableOpacity>

            <TextInput
              style={styles.input}
              placeholder={
                language === 'vi' ? 'Nh·∫≠p tin nh·∫Øn...' :
                language === 'en' ? 'Type a message...' :
                '·ûú·û∂·ûô·ûü·û∂·ûö...'
              }
              value={inputText}
              onChangeText={setInputText}
              multiline
              maxLength={500}
              editable={!isLoading && !isAnalyzingImage}
            />

            <VoiceRecorder
              language={language}
              onTranscriptionComplete={handleVoiceRecorded}
            />

            <TouchableOpacity
              style={[
                styles.sendButton,
                !inputText.trim() && styles.sendButtonDisabled
              ]}
              onPress={handleSendMessage}
              disabled={!inputText.trim() || isLoading || isAnalyzingImage}
            >
              <Ionicons
                name="send"
                size={24}
                color={inputText.trim() ? '#FF8DAD' : '#CCC'}
              />
            </TouchableOpacity>
          </View>
        </View>
      </KeyboardAvoidingView>

      {/* Image Preview Modal */}
      <Modal
        visible={showImageModal}
        transparent={true}
        animationType="slide"
        onRequestClose={() => setShowImageModal(false)}
      >
        <View style={styles.modalOverlay}>
          <View style={styles.modalContent}>
            <View style={styles.modalHeader}>
              <Text style={styles.modalTitle}>
                {language === 'vi' ? 'Xem tr∆∞·ªõc ·∫£nh' : 'Image Preview'}
              </Text>
              <TouchableOpacity
                onPress={() => {
                  setShowImageModal(false);
                  setSelectedImage(null);
                }}
              >
                <Ionicons name="close" size={24} color="#666" />
              </TouchableOpacity>
            </View>

            {selectedImage && (
              <Image
                source={{ uri: selectedImage.uri }}
                style={styles.previewImage}
                resizeMode="contain"
              />
            )}

            <Text style={styles.modalHint}>
              {language === 'vi'
                ? 'G·ª≠i ·∫£nh n√†y ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung v√† ki·ªÉm tra d·∫•u hi·ªáu l·ª´a ƒë·∫£o'
                : 'Send this image to analyze content and check for fraud indicators'}
            </Text>

            <View style={styles.modalButtons}>
              <TouchableOpacity
                style={styles.cancelButton}
                onPress={() => {
                  setShowImageModal(false);
                  setSelectedImage(null);
                }}
              >
                <Text style={styles.cancelButtonText}>
                  {language === 'vi' ? 'H·ªßy' : 'Cancel'}
                </Text>
              </TouchableOpacity>

              <TouchableOpacity
                style={styles.analyzeButton}
                onPress={handleAnalyzeImage}
              >
                <Text style={styles.analyzeButtonText}>
                  {language === 'vi' ? 'G·ª≠i ph√¢n t√≠ch' : 'Analyze'}
                </Text>
              </TouchableOpacity>
            </View>
          </View>
        </View>
      </Modal>
    </LinearGradient>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    paddingTop: 50,
    paddingBottom: 15,
    paddingHorizontal: 20,
    backgroundColor: 'rgba(255, 255, 255, 0.5)'
  },
  backButton: {
    padding: 5
  },
  headerTitleContainer: {
    flex: 1,
    alignItems: 'center'
  },
  headerTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#FF8DAD'
  },
  headerSubtitle: {
    fontSize: 12,
    color: '#FF6B99'
  },
  infoButton: {
    padding: 5
  },
  messagesContainer: {
    flex: 1
  },
  messagesContent: {
    padding: 15,
    paddingBottom: 10
  },
  loadingContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    alignSelf: 'flex-start',
    backgroundColor: 'rgba(255, 255, 255, 0.7)',
    borderRadius: 20,
    paddingHorizontal: 15,
    paddingVertical: 10,
    marginTop: 10
  },
  loadingText: {
    marginLeft: 10,
    color: '#FF8DAD',
    fontSize: 14
  },
  inputContainer: {
    paddingHorizontal: 15,
    paddingVertical: 10,
    backgroundColor: 'rgba(255, 255, 255, 0.5)'
  },
  inputWrapper: {
    flexDirection: 'row',
    alignItems: 'flex-end',
    backgroundColor: '#FFF',
    borderRadius: 25,
    paddingHorizontal: 15,
    paddingVertical: 8,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2
    },
    shadowOpacity: 0.25,
    shadowRadius: 3.84,
    elevation: 5
  },
  input: {
    flex: 1,
    maxHeight: 100,
    fontSize: 16,
    color: '#333',
    paddingVertical: 5
  },
  sendButton: {
    marginLeft: 10,
    padding: 5
  },
  sendButtonDisabled: {
    opacity: 0.5
  },
  cameraButton: {
    marginRight: 10,
    padding: 5
  },
  // Modal styles
  modalOverlay: {
    flex: 1,
    backgroundColor: 'rgba(0, 0, 0, 0.5)',
    justifyContent: 'center',
    alignItems: 'center'
  },
  modalContent: {
    backgroundColor: '#FFF',
    borderRadius: 16,
    padding: 20,
    width: '90%',
    maxHeight: '80%'
  },
  modalHeader: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    marginBottom: 15
  },
  modalTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#FF8DAD'
  },
  previewImage: {
    width: '100%',
    height: 300,
    borderRadius: 8,
    marginBottom: 15
  },
  modalHint: {
    textAlign: 'center',
    color: '#666',
    fontSize: 14,
    marginBottom: 20
  },
  modalButtons: {
    flexDirection: 'row',
    justifyContent: 'space-between'
  },
  cancelButton: {
    flex: 1,
    padding: 15,
    borderRadius: 8,
    backgroundColor: '#F5F5F5',
    marginRight: 10,
    alignItems: 'center'
  },
  cancelButtonText: {
    color: '#666',
    fontSize: 16,
    fontWeight: '600'
  },
  analyzeButton: {
    flex: 1,
    padding: 15,
    borderRadius: 8,
    backgroundColor: '#FF8DAD',
    marginLeft: 10,
    alignItems: 'center'
  },
  analyzeButtonText: {
    color: '#FFF',
    fontSize: 16,
    fontWeight: '600'
  }
});
